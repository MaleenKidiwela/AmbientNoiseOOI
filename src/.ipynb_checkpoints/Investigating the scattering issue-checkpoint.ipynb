{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c08dbbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_causal_acausal (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SeisNoise, SeisIO, Plots\n",
    "using Dates \n",
    "using Plots\n",
    "using SeisDvv\n",
    "using CSV\n",
    "using Statistics\n",
    "using LinearAlgebra\n",
    "using Deconvolution\n",
    "\n",
    "\n",
    "# Function to create an evenly spaced array\n",
    "function evenly_spaced(a, b, n)\n",
    "    h = (b - a) / (n - 1)\n",
    "    collect(a:h:b)\n",
    "end\n",
    "\n",
    "\n",
    "# Averaging function for causal and acausal parts\n",
    "function average_causal_acausal(corr, time)\n",
    "    averaged_corr = copy(corr)\n",
    "    causal_index = findfirst(time .>= 0)\n",
    "    acausal_index = findlast(time .< 0)\n",
    "\n",
    "    for k in 1:causal_index-1\n",
    "        if acausal_index - k + 1 > 0\n",
    "            averaged_corr[causal_index + k - 1] = (averaged_corr[acausal_index - k + 1] + averaged_corr[causal_index + k - 1]) / 2\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return averaged_corr\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42ec6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_corr_data = dailystk.corr\n",
    "\n",
    "# Determine the indices for the noise-dominant sections\n",
    "# For instance, taking sections far from the peak\n",
    "num_points = size(cross_corr_data, 1)\n",
    "middle = div(num_points, 2)\n",
    "noise_section_indices = 1:(middle - 100)  # Example: avoiding 100 points around the peak\n",
    "\n",
    "# Extract the noise section\n",
    "noise_section = cross_corr_data[noise_section_indices, :]\n",
    "\n",
    "# Calculate the variance (noise power) across all correlations\n",
    "# You might want to average this over all the available correlations\n",
    "noise_power = mean(var(noise_section, dims=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b41f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ncf_denoise function\n",
    "function ncf_denoise(img_to_denoise::Matrix{Float32}, mdate::Int64, ntau::Int64, nsv::Int64, nsv_to_rm::Int64, use_wiener::Bool, noise_power::Float64)\n",
    "    m, n = size(img_to_denoise)\n",
    "    nsv = min(nsv, m, n)\n",
    "\n",
    "    U, s, V = svd(img_to_denoise)\n",
    "    Xwiener = zeros(Float32, size(img_to_denoise))  # Ensure the type is Float32\n",
    "\n",
    "    for kk in (nsv_to_rm + 1):nsv\n",
    "        SV = Diagonal([kk == i ? s[kk] : 0 for i in 1:min(m, n)])\n",
    "\n",
    "        X = U * SV * V'\n",
    "\n",
    "        if use_wiener\n",
    "            # Convert X to Float64 if necessary\n",
    "            X64 = convert(Matrix{Float64}, X)\n",
    "            Xwiener += wiener(X64, X64, noise_power)\n",
    "        else\n",
    "            Xwiener += X\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if use_wiener\n",
    "        # Final Wiener filter application, converting Xwiener to Float64\n",
    "        Xwiener64 = convert(Matrix{Float64}, Xwiener)\n",
    "        return wiener(Xwiener64, Xwiener64, noise_power)\n",
    "    else\n",
    "        return Xwiener\n",
    "    end\n",
    "end\n",
    "\n",
    "# Preprocess your data\n",
    "mnf = 0.1\n",
    "mxf = 0.3\n",
    "ndaystack = 10\n",
    "inter = Day(ndaystack)\n",
    "\n",
    "d = load_corr(\"/data/wsd02/maleen_data/C_test/OO.HYSB1..BHZ.OO.HYSB1..BHE.jld2\", \"ZE\")\n",
    "allstk = stack(d, allstack=true)\n",
    "clean_up!(allstk, mnf, mxf)\n",
    "abs_max!(allstk)\n",
    "dailystk = stack(d, interval=inter)\n",
    "clean_up!(dailystk, mnf, mxf)\n",
    "abs_max!(dailystk)\n",
    "\n",
    "# Denoise allstk and dailystk and store in the corrdata\n",
    "mdate = 5\n",
    "ntau = 5\n",
    "nsv = 25\n",
    "nsv_to_rm = 0\n",
    "use_wiener = true\n",
    "\n",
    "# Estimate of the noise power (adjust based on your data)\n",
    "noise_power = 0.03  # Example value, adjust as needed\n",
    "\n",
    "allstk.corr = ncf_denoise(allstk.corr, mdate, ntau, nsv, nsv_to_rm, use_wiener, noise_power);\n",
    "dailystk.corr = ncf_denoise(dailystk.corr, mdate, ntau, nsv, nsv_to_rm, use_wiener, noise_power);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnf = 0.1\n",
    "mxf = 0.3\n",
    "ndaystack = 10\n",
    "inter = Day(ndaystack)\n",
    "\n",
    "d=load_corr(\"/data/wsd02/maleen_data/C_test/OO.HYSB1..BHZ.OO.HYSB1..BHE.jld2\",\"ZE\")\n",
    "#d=load_corr(\"/data/wsd02/maleen_data/Correl_seismic/OO.HYSB1..BHZ.OO.HYSB1..BHE.jld2\",\"ZE\")\n",
    "allstk=stack(d,allstack=true)\n",
    "clean_up!(allstk,mnf,mxf)\n",
    "abs_max!(allstk)\n",
    "dailystk=stack(d,interval=inter)\n",
    "clean_up!(dailystk,mnf,mxf)\n",
    "abs_max!(dailystk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad598158",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dailystk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac160a",
   "metadata": {},
   "source": [
    "### shifting peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74678026",
   "metadata": {},
   "outputs": [],
   "source": [
    "time=evenly_spaced(-100,100,size(dailystk.corr,1))\n",
    "# Function to find the index of zero-lag peak\n",
    "function find_zero_lag_peak_index(signal, time)\n",
    "    zero_lag_index = findfirst(x -> x == 0, time)\n",
    "    #zero_lag_index = 3800\n",
    "    window_size = 50 # Adjust this window size as needed\n",
    "    window_indices = max(1, zero_lag_index - window_size):min(length(signal), zero_lag_index + window_size)\n",
    "    peak_index = argmax(signal[window_indices]) + window_indices[1] - 1\n",
    "    return peak_index\n",
    "end\n",
    "\n",
    "# The reference signal from allstk\n",
    "S1 = allstk.corr[:, 1] # Always use the first column of allstk.corr\n",
    "\n",
    "# Loop through each correlation function in dailystk\n",
    "for i in 1:size(dailystk.corr, 2)\n",
    "    S2 = dailystk.corr[:, i]\n",
    "\n",
    "    peak_index_S1 = find_zero_lag_peak_index(S1, time)\n",
    "    peak_index_S2 = find_zero_lag_peak_index(S2, time)\n",
    "    shift_amount = peak_index_S1 - peak_index_S2\n",
    "\n",
    "    # Shift S2 and pad with zeros\n",
    "    S2_shifted = circshift(S2, shift_amount)\n",
    "    if shift_amount > 0\n",
    "        S2_shifted[1:shift_amount] .= 0\n",
    "    else\n",
    "        S2_shifted[end+shift_amount+1:end] .= 0\n",
    "    end\n",
    "\n",
    "    # Store the shifted signal back in dailystk.corr\n",
    "    dailystk.corr[:, i] = S2_shifted\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "time = evenly_spaced(-100, 100, size(allstk.corr, 1))\n",
    "# Number of correlation functions to plot\n",
    "num_funcs_to_plot = 75\n",
    "\n",
    "# Initialize the plot\n",
    "p = plot(size=(800, 600), legend=false)\n",
    "\n",
    "# Looping through the first 50 correlation functions\n",
    "for i in 1:num_funcs_to_plot\n",
    "    # Accessing the i-th correlation function from the corr matrix\n",
    "    corr_function = dailystk.corr[:, i]\n",
    "\n",
    "    # Finding the index of the most minimum value in the correlation function\n",
    "    min_index = argmin(corr_function)\n",
    "    min_value = corr_function[min_index]\n",
    "\n",
    "    # Plotting the correlation function, offsetting each by 'i' for clarity\n",
    "    plot!(p, time,corr_function .+ i, color=:black, label=\"Correlation Function $(i)\")\n",
    "\n",
    "    # Adding a short vertical line at the minimum value\n",
    "    # The line extends slightly above and below the actual minimum point\n",
    "    line_y_values = [min_value + i - 0.5, min_value + i + 0.5]  # Adjust 0.1 as needed for visibility\n",
    "    plot!(p, [time[min_index], time[min_index]], line_y_values, color=:red, lw=1,dpi=300)\n",
    "end\n",
    "\n",
    "# Setting labels and title\n",
    "xlabel!(p, \"Time Lag\")\n",
    "ylabel!(p, \"Correlation Function\")\n",
    "title!(p, \"First 50 Stacked Correlation Functions from dailystk with Minima Marked\")\n",
    "\n",
    "# Displaying the plot\n",
    "display(p)\n",
    "savefig(p, \"dailystacks.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05db9946",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "# Assuming we have 222 correlation functions in total\n",
    "total_funcs = length(dailystk)\n",
    "\n",
    "# Initialize arrays to store the indices (time lags) of minima\n",
    "min_lag_indices = []\n",
    "\n",
    "# Extracting the indices (time lags) of the minima\n",
    "for i in 1:total_funcs\n",
    "    # Accessing the i-th correlation function from the corr matrix\n",
    "    corr_function = dailystk.corr[:, i]\n",
    "\n",
    "    # Finding the index of the most minimum value in the correlation function\n",
    "    min_index = argmin(corr_function)\n",
    "\n",
    "    # Including only the indices (time lags) less than or equal to 3950\n",
    "    if min_index <= 3920\n",
    "        push!(min_lag_indices, min_index)\n",
    "    else\n",
    "        push!(min_lag_indices, NaN)  # Use NaN for values above 3950 to exclude them from the plot\n",
    "    end\n",
    "end\n",
    "\n",
    "# Create the plot with the desired size and explicit margins\n",
    "p_min_lag = plot(dt, (min_lag_indices/40).-100, title=\"Time Lag of Minimum Value\",\n",
    "                 xlabel=\"Correlation Function Number\", ylabel=\"Time Lag of Minimum Value\",\n",
    "                 legend=false, color=:blue, marker=:circle, size=(1000, 400),dpi=300)\n",
    "\n",
    "# Adjust the margins. Since direct pixel specification is causing an error,\n",
    "# you can try using `Plots.mm` or `Plots.px` to specify the units.\n",
    "p_min_lag = plot!(p_min_lag, margin=5Plots.mm)  # This should be equivalent to 5mm margin.\n",
    "\n",
    "# Save the plot to a file\n",
    "#savefig(p_min_lag, \"min_lag_plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ca0954",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=scatter((min_lag_indices/40).-100,dvt,ylabel=\"DV/V\", xlabel=\"Time Lag of Minimum Value\",size=(1000, 400),dpi=300,margin=5Plots.mm,legend=false)\n",
    "savefig(a, \"lag_dvv plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=40.0     # sample frequency\n",
    "win_len=5.0  # sliding window length\n",
    "win_step=2.5 # sliding window step\n",
    "j=size(dailystk.corr,2)\n",
    "dvt=zeros(j)\n",
    "cct=zeros(j)\n",
    "cctb=zeros(j)\n",
    "tmin = 37.\n",
    "tmax = 60.\n",
    "dmn = -0.01\n",
    "dmx = 0.01\n",
    "\n",
    "for i in 1:j\n",
    "    S1=Array(allstk.corr[:])\n",
    "    S2=Array(dailystk.corr[:,i])\n",
    "    rel_tmin_index = Int(floor((tmin + 100) * fs))\n",
    "    rel_tmax_index = Int(floor((tmax + 100) * fs))\n",
    "\n",
    "    window = collect(rel_tmin_index:rel_tmax_index)\n",
    "    fmin = mnf\n",
    "    fmax = mxf\n",
    "\n",
    "    function evenly_spaced(a, b, n)\n",
    "        h = (b-a)/(n-1)\n",
    "        collect(a:h:b)\n",
    "    end\n",
    "\n",
    "    time=evenly_spaced(-100,100,size(dailystk.corr,1))\n",
    "\n",
    "    dvv_ts, cc_ts, cdp_Ts, eps_ts, err_ts, allC_ts = SeisDvv.stretching(S1, S2, time, window, fmin, fmax, dvmin=dmn, dvmax=dmx, ntrial=1000);\n",
    "    #dvmin=-0.01, dvmax=0.01\n",
    "    dvt[i]=dvv_ts\n",
    "    cct[i]=cc_ts\n",
    "    cctb[i]=cdp_Ts\n",
    "    \n",
    "end\n",
    "\n",
    "dt = map(unix2datetime, dailystk.t);\n",
    "# Assuming datetime_vector is your 71-element Vector{DateTime} \n",
    "# and float_vector is your 71-element Vector{Float64}\n",
    "datetime_vector = dt;  # fill this with your data\n",
    "float_vector = dvt;  # fill this with your data\n",
    "cctfilter = cct;\n",
    "\n",
    "# Combine the vectors into a named tuple which CSV.File will interpret as a table\n",
    "data = (DateTime=datetime_vector, Float=float_vector,cct);\n",
    "\n",
    "# Set the threshold value\n",
    "threshold = 0.80\n",
    "\n",
    "# Filter the datetime and float vectors based on the threshold\n",
    "filtered_indices = cct .>= threshold;\n",
    "datetime_vector = datetime_vector[filtered_indices];\n",
    "float_vector = float_vector[filtered_indices];\n",
    "cctfilter = cct[filtered_indices];\n",
    "\n",
    "# Calculate the Interquartile Range (IQR)\n",
    "Q1 = quantile(float_vector, 0.20)\n",
    "Q3 = quantile(float_vector, 0.80)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate the lower and upper bounds to filter the outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the vectors to remove the outliers\n",
    "dtf = DateTime[]\n",
    "dvtf = Float64[]\n",
    "cctf = Float64[]\n",
    "for i in 1:length(float_vector)\n",
    "    if float_vector[i] >= lower_bound && float_vector[i] <= upper_bound\n",
    "        push!(dtf, datetime_vector[i])\n",
    "        push!(dvtf, float_vector[i])\n",
    "        push!(cctf, cctfilter[i])\n",
    "    end\n",
    "end\n",
    "# Calculate the mean and standard deviation\n",
    "mean_value = mean(cct)\n",
    "std_deviation = std(dvtf)\n",
    "\n",
    "# Print the results\n",
    "println(\"Mean of the float vector: $mean_value\")\n",
    "println(\"Standard deviation of the float vector: $std_deviation\")\n",
    "\n",
    "# Sample datetime_vector and dvtf\n",
    "datetime_vector = dtf\n",
    "\n",
    "# Find the minimum and maximum dates in the datetime_vector\n",
    "min_date = minimum(datetime_vector)\n",
    "max_date = maximum(datetime_vector)\n",
    "\n",
    "# Generate all dates in the date rangeI'\n",
    "all_dates = collect(min_date:Day(ndaystack):max_date)\n",
    "\n",
    "# Find the dates that are in all_dates but not in datetime_vector (considering only the date part)\n",
    "missing_dates = setdiff(all_dates, datetime_vector)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming dt, dvt, cct, and dailystk are defined\n",
    "#dt = map(unix2datetime, dailystk.t)\n",
    "ticks = dtf[1:10:end]\n",
    "tick = Dates.format.(ticks, \"yyyy-mm-dd\")\n",
    "\n",
    "# First subplot\n",
    "p1 = plot(scatter(dtf, dvtf), seriestype = :line, xticks = (ticks, tick), xrot = -30, ylabel=\"dv/v %\", legend=false)\n",
    "plot!(dtf, dvtf, seriestype = :line, xticks = (ticks, tick), xrot = -30, legend=false)\n",
    "# For each missing date, add a vertical line to the plot\n",
    "#for date in missing_dates\n",
    "#    vline!(p1, [DateTime(date)], linecolor=:red, linewidth=2, linealpha=0.5, label=\"Missing Date\")\n",
    "#end\n",
    "\n",
    "\n",
    "# Second subplot\n",
    "p2 = plot(dtf, cctf, seriestype = :line, ylim = [0, 1], label = \"cc\", xticks = (ticks, tick), xrot = -30, left_margin = 10Plots.mm, ylabel=\"cc\", xlabel=\"Date\", legend=false)\n",
    "hline!([0.8], label=\"Threshold\", width=2, color=:red) # Adding a horizontal line at y=0.8\n",
    "\n",
    "# Third subplot\n",
    "p3 = plot(dailystk, left_margin = 10Plots.mm)\n",
    "\n",
    "# The layout now specifies a grid of 3 rows and 1 column and gives the third plot even more vertical space compared to the first two.\n",
    "l = @layout([a{0.3h}; b{0.2h}; c{0.5h}])\n",
    "\n",
    "# Combine the plots\n",
    "final_plot = plot(p1, p2, p3, layout = l, size = (1100, 1000), left_margin = 20Plots.mm, right_margin = 5Plots.mm)\n",
    "\n",
    "# Save the plot\n",
    "savefig(final_plot, \"$(d.name)_t$(tmin)-$(tmax)_freq$(mnf)-$(mxf)_stk$(ndaystack)clip_0.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab391e",
   "metadata": {},
   "source": [
    "## Averaging code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e60c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using SeisNoise, SeisIO, Plots\n",
    "using Dates\n",
    "using SeisDvv\n",
    "using CSV\n",
    "using Statistics\n",
    "\n",
    "# Initial setup\n",
    "mnf = 0.1\n",
    "mxf = 0.3\n",
    "ndaystack = 10\n",
    "inter = Day(ndaystack)\n",
    "\n",
    "# Load correlation data\n",
    "#d = load_corr(\"/data/wsd02/maleen_data/C_test/OO.HYSB1..BHZ.OO.HYSB1..BHN.jld2\", \"ZN\")\n",
    "d =load_corr(\"/data/wsd02/maleen_data/C_test/OO.HYSB1..BHZ.OO.HYSB1..BHE.jld2\",\"ZE\")\n",
    "allstk = stack(d, allstack=true)\n",
    "clean_up!(allstk, mnf, mxf)\n",
    "abs_max!(allstk)\n",
    "dailystk = stack(d, interval=inter)\n",
    "clean_up!(dailystk, mnf, mxf)\n",
    "abs_max!(dailystk)\n",
    "\n",
    "# Parameters for DV/V calculation\n",
    "fs = 40.0     # Sample frequency\n",
    "tmin = 10.0\n",
    "tmax = 60.0\n",
    "dmn = -0.1\n",
    "dmx = 0.1\n",
    "j = size(dailystk.corr, 2)\n",
    "\n",
    "# Initializing arrays for results\n",
    "dvt = zeros(j)\n",
    "cct = zeros(j)\n",
    "cctb = zeros(j)\n",
    "\n",
    "\n",
    "# Time vector for the correlation function\n",
    "time = evenly_spaced(-100, 100, size(allstk.corr, 1))\n",
    "\n",
    "# Apply averaging to S1\n",
    "S1_averaged = average_causal_acausal(Array(allstk.corr[:]), time)\n",
    "\n",
    "for i in 1:j\n",
    "    S2 = Array(dailystk.corr[:,i])\n",
    "\n",
    "    # Apply averaging to S2\n",
    "    S2_averaged = average_causal_acausal(S2, time)\n",
    "\n",
    "    # Define the window for DV/V calculation\n",
    "    rel_tmin_index = Int(floor((tmin + 100) * fs))\n",
    "    rel_tmax_index = Int(floor((tmax + 100) * fs))\n",
    "    window = collect(rel_tmin_index:rel_tmax_index)\n",
    "\n",
    "    # DV/V calculation using SeisDvv\n",
    "    dvv_ts, cc_ts, cdp_Ts, eps_ts, err_ts, allC_ts = SeisDvv.stretching(S1_averaged, S2_averaged, time, window, mnf, mxf, dvmin=dmn, dvmax=dmx, ntrial=100)\n",
    "\n",
    "    # Storing results\n",
    "    dvt[i] = dvv_ts\n",
    "    cct[i] = cc_ts\n",
    "    cctb[i] = cdp_Ts\n",
    "end\n",
    "\n",
    "dt = map(unix2datetime, dailystk.t);\n",
    "# Assuming datetime_vector is your 71-element Vector{DateTime} \n",
    "# and float_vector is your 71-element Vector{Float64}\n",
    "datetime_vector = dt;  # fill this with your data\n",
    "float_vector = dvt;  # fill this with your data\n",
    "cctfilter = cct;\n",
    "\n",
    "# Combine the vectors into a named tuple which CSV.File will interpret as a table\n",
    "data = (DateTime=datetime_vector, Float=float_vector,cct);\n",
    "\n",
    "# Set the threshold value\n",
    "threshold = 0.80\n",
    "\n",
    "# Filter the datetime and float vectors based on the threshold\n",
    "filtered_indices = cct .>= threshold;\n",
    "datetime_vector = datetime_vector[filtered_indices];\n",
    "float_vector = float_vector[filtered_indices];\n",
    "cctfilter = cct[filtered_indices];\n",
    "\n",
    "# Calculate the Interquartile Range (IQR)\n",
    "Q1 = quantile(float_vector, 0.20)\n",
    "Q3 = quantile(float_vector, 0.80)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate the lower and upper bounds to filter the outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the vectors to remove the outliers\n",
    "dtf = DateTime[]\n",
    "dvtf = Float64[]\n",
    "cctf = Float64[]\n",
    "for i in 1:length(float_vector)\n",
    "    if float_vector[i] >= lower_bound && float_vector[i] <= upper_bound\n",
    "        push!(dtf, datetime_vector[i])\n",
    "        push!(dvtf, float_vector[i])\n",
    "        push!(cctf, cctfilter[i])\n",
    "    end\n",
    "end\n",
    "# Calculate the mean and standard deviation\n",
    "mean_value = mean(cct)\n",
    "std_deviation = std(dvtf)\n",
    "\n",
    "# Print the results\n",
    "println(\"Mean of the float vector: $mean_value\")\n",
    "println(\"Standard deviation of the float vector: $std_deviation\")\n",
    "\n",
    "# Sample datetime_vector and dvtf\n",
    "datetime_vector = dtf\n",
    "\n",
    "# Find the minimum and maximum dates in the datetime_vector\n",
    "min_date = minimum(datetime_vector)\n",
    "max_date = maximum(datetime_vector)\n",
    "\n",
    "# Generate all dates in the date rangeI'\n",
    "all_dates = collect(min_date:Day(ndaystack):max_date)\n",
    "\n",
    "# Find the dates that are in all_dates but not in datetime_vector (considering only the date part)\n",
    "missing_dates = setdiff(all_dates, datetime_vector)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming dt, dvt, cct, and dailystk are defined\n",
    "#dt = map(unix2datetime, dailystk.t)\n",
    "ticks = dtf[1:10:end]\n",
    "tick = Dates.format.(ticks, \"yyyy-mm-dd\")\n",
    "\n",
    "# First subplot\n",
    "p1 = plot(scatter(dtf, dvtf), seriestype = :line, xticks = (ticks, tick), xrot = -30, ylabel=\"dv/v %\", legend=false)\n",
    "plot!(dtf, dvtf, seriestype = :line, xticks = (ticks, tick), xrot = -30, legend=false)\n",
    "# For each missing date, add a vertical line to the plot\n",
    "#for date in missing_dates\n",
    "#    vline!(p1, [DateTime(date)], linecolor=:red, linewidth=2, linealpha=0.5, label=\"Missing Date\")\n",
    "#end\n",
    "\n",
    "\n",
    "# Second subplot\n",
    "p2 = plot(dtf, cctf, seriestype = :line, ylim = [0, 1], label = \"cc\", xticks = (ticks, tick), xrot = -30, left_margin = 10Plots.mm, ylabel=\"cc\", xlabel=\"Date\", legend=false)\n",
    "hline!([0.8], label=\"Threshold\", width=2, color=:red) # Adding a horizontal line at y=0.8\n",
    "\n",
    "# Third subplot\n",
    "p3 = plot(dailystk, left_margin = 10Plots.mm)\n",
    "\n",
    "# The layout now specifies a grid of 3 rows and 1 column and gives the third plot even more vertical space compared to the first two.\n",
    "l = @layout([a{0.3h}; b{0.2h}; c{0.5h}])\n",
    "\n",
    "# Combine the plots\n",
    "final_plot = plot(p1, p2, p3, layout = l, size = (1100, 1000), left_margin = 20Plots.mm, right_margin = 5Plots.mm)\n",
    "\n",
    "# Save the plot\n",
    "savefig(final_plot, \"$(d.name)_t$(tmin)-$(tmax)_freq$(mnf)-$(mxf)_stk$(ndaystack)clip_avg_1.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd92b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for DV/V calculation\n",
    "fs = 40.0     # Sample frequency\n",
    "tmin = 5.0\n",
    "tmax = 60.0\n",
    "dmn = -0.1\n",
    "dmx = 0.1\n",
    "j = size(dailystk.corr, 2)\n",
    "\n",
    "# Initializing arrays for results\n",
    "dvt = zeros(j)\n",
    "cct = zeros(j)\n",
    "cctb = zeros(j)\n",
    "\n",
    "# Function to create an evenly spaced array\n",
    "function evenly_spaced(a, b, n)\n",
    "    h = (b - a) / (n - 1)\n",
    "    collect(a:h:b)\n",
    "end\n",
    "\n",
    "# Averaging function for causal and acausal parts\n",
    "function average_causal_acausal(corr, time)\n",
    "    averaged_corr = copy(corr)\n",
    "    causal_index = findfirst(time .>= 0)\n",
    "    acausal_index = findlast(time .< 0)\n",
    "\n",
    "    for k in 1:causal_index-1\n",
    "        if acausal_index - k + 1 > 0\n",
    "            averaged_corr[causal_index + k - 1] = (averaged_corr[acausal_index - k + 1] + averaged_corr[causal_index + k - 1]) / 2\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return averaged_corr\n",
    "end\n",
    "\n",
    "# Time vector for the correlation function\n",
    "time = evenly_spaced(-100, 100, size(allstk.corr, 1))\n",
    "\n",
    "# Apply averaging to S1\n",
    "S1_averaged = average_causal_acausal(Array(allstk.corr[:]), time)\n",
    "\n",
    "for i in 1:j\n",
    "    S2 = Array(dailystk.corr[:,i])\n",
    "\n",
    "    # Apply averaging to S2\n",
    "    S2_averaged = average_causal_acausal(S2, time)\n",
    "\n",
    "    # Define the window for DV/V calculation\n",
    "    rel_tmin_index = Int(floor((tmin + 100) * fs))\n",
    "    rel_tmax_index = Int(floor((tmax + 100) * fs))\n",
    "    window = collect(rel_tmin_index:rel_tmax_index)\n",
    "\n",
    "    # DV/V calculation using SeisDvv\n",
    "    dvv_ts, cc_ts, cdp_Ts, eps_ts, err_ts, allC_ts = SeisDvv.stretching(S1_averaged, S2_averaged, time, window, mnf, mxf, dvmin=dmn, dvmax=dmx, ntrial=100)\n",
    "\n",
    "    # Storing results\n",
    "    dvt[i] = dvv_ts\n",
    "    cct[i] = cc_ts\n",
    "    cctb[i] = cdp_Ts\n",
    "end\n",
    "\n",
    "dt = map(unix2datetime, dailystk.t);\n",
    "# Assuming datetime_vector is your 71-element Vector{DateTime} \n",
    "# and float_vector is your 71-element Vector{Float64}\n",
    "datetime_vector = dt;  # fill this with your data\n",
    "float_vector = dvt;  # fill this with your data\n",
    "cctfilter = cct;\n",
    "\n",
    "# Combine the vectors into a named tuple which CSV.File will interpret as a table\n",
    "data = (DateTime=datetime_vector, Float=float_vector,cct);\n",
    "\n",
    "# Set the threshold value\n",
    "threshold = 0.80\n",
    "\n",
    "# Filter the datetime and float vectors based on the threshold\n",
    "filtered_indices = cct .>= threshold;\n",
    "datetime_vector = datetime_vector[filtered_indices];\n",
    "float_vector = float_vector[filtered_indices];\n",
    "cctfilter = cct[filtered_indices];\n",
    "\n",
    "# Calculate the Interquartile Range (IQR)\n",
    "Q1 = quantile(float_vector, 0.20)\n",
    "Q3 = quantile(float_vector, 0.80)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate the lower and upper bounds to filter the outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the vectors to remove the outliers\n",
    "dtf = DateTime[]\n",
    "dvtf = Float64[]\n",
    "cctf = Float64[]\n",
    "for i in 1:length(float_vector)\n",
    "    if float_vector[i] >= lower_bound && float_vector[i] <= upper_bound\n",
    "        push!(dtf, datetime_vector[i])\n",
    "        push!(dvtf, float_vector[i])\n",
    "        push!(cctf, cctfilter[i])\n",
    "    end\n",
    "end\n",
    "# Calculate the mean and standard deviation\n",
    "mean_value = mean(cct)\n",
    "std_deviation = std(dvtf)\n",
    "\n",
    "# Print the results\n",
    "println(\"Mean of the float vector: $mean_value\")\n",
    "println(\"Standard deviation of the float vector: $std_deviation\")\n",
    "\n",
    "# Sample datetime_vector and dvtf\n",
    "datetime_vector = dtf\n",
    "\n",
    "# Find the minimum and maximum dates in the datetime_vector\n",
    "min_date = minimum(datetime_vector)\n",
    "max_date = maximum(datetime_vector)\n",
    "\n",
    "# Generate all dates in the date rangeI'\n",
    "all_dates = collect(min_date:Day(ndaystack):max_date)\n",
    "\n",
    "# Find the dates that are in all_dates but not in datetime_vector (considering only the date part)\n",
    "missing_dates = setdiff(all_dates, datetime_vector)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming dt, dvt, cct, and dailystk are defined\n",
    "#dt = map(unix2datetime, dailystk.t)\n",
    "ticks = dtf[1:10:end]\n",
    "tick = Dates.format.(ticks, \"yyyy-mm-dd\")\n",
    "\n",
    "# First subplot\n",
    "p1 = plot(scatter(dtf, dvtf), seriestype = :line, xticks = (ticks, tick), xrot = -30, ylabel=\"dv/v %\", legend=false)\n",
    "plot!(dtf, dvtf, seriestype = :line, xticks = (ticks, tick), xrot = -30, legend=false)\n",
    "# For each missing date, add a vertical line to the plot\n",
    "#for date in missing_dates\n",
    "#    vline!(p1, [DateTime(date)], linecolor=:red, linewidth=2, linealpha=0.5, label=\"Missing Date\")\n",
    "#end\n",
    "\n",
    "\n",
    "# Second subplot\n",
    "p2 = plot(dtf, cctf, seriestype = :line, ylim = [0, 1], label = \"cc\", xticks = (ticks, tick), xrot = -30, left_margin = 10Plots.mm, ylabel=\"cc\", xlabel=\"Date\", legend=false)\n",
    "hline!([0.8], label=\"Threshold\", width=2, color=:red) # Adding a horizontal line at y=0.8\n",
    "\n",
    "# Third subplot\n",
    "p3 = plot(dailystk, left_margin = 10Plots.mm)\n",
    "\n",
    "# The layout now specifies a grid of 3 rows and 1 column and gives the third plot even more vertical space compared to the first two.\n",
    "l = @layout([a{0.3h}; b{0.2h}; c{0.5h}])\n",
    "\n",
    "# Combine the plots\n",
    "final_plot = plot(p1, p2, p3, layout = l, size = (1100, 1000), left_margin = 20Plots.mm, right_margin = 5Plots.mm)\n",
    "\n",
    "# Save the plot\n",
    "savefig(final_plot, \"$(d.name)_t$(tmin)-$(tmax)_freq$(mnf)-$(mxf)_stk$(ndaystack)dsv_avg.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa5e5a6",
   "metadata": {},
   "source": [
    "### Dynamic Time Warping Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca9fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnf = 0.1\n",
    "mxf = 0.3\n",
    "ndaystack = 10\n",
    "inter = Day(ndaystack)\n",
    "\n",
    "d=load_corr(\"/data/wsd02/maleen_data/C_test/OO.HYSB1..BHZ.OO.HYSB1..BHE.jld2\",\"ZE\")\n",
    "allstk=stack(d,allstack=true)\n",
    "clean_up!(allstk,mnf,mxf)\n",
    "abs_max!(allstk)\n",
    "dailystk=stack(d,interval=inter)\n",
    "clean_up!(dailystk,mnf,mxf)\n",
    "abs_max!(dailystk)\n",
    "\n",
    "fs=40.0     # sample frequency\n",
    "j=size(dailystk.corr,2)\n",
    "dvt=zeros(j)\n",
    "cct=zeros(j)\n",
    "cctb=zeros(j)\n",
    "tmin = 20.\n",
    "tmax = 80.\n",
    "\n",
    "\n",
    "for i in 1:j\n",
    "    S1=Array(allstk.corr[:])\n",
    "    S2=Array(dailystk.corr[:,i])\n",
    "    rel_tmin_index = Int(floor((tmin + 100) * fs))\n",
    "    rel_tmax_index = Int(floor((tmax + 100) * fs))\n",
    "\n",
    "    window = collect(rel_tmin_index:rel_tmax_index)\n",
    "    fmin = mnf\n",
    "    fmax = mxf\n",
    "\n",
    "    function evenly_spaced(a, b, n)\n",
    "        h = (b-a)/(n-1)\n",
    "        collect(a:h:b)\n",
    "    end\n",
    "\n",
    "    time=evenly_spaced(-100,100,size(dailystk.corr,1)) \n",
    "    \n",
    "    dvv_dtw, dvv_err_dtw, int_dtw, int_err_dtw, dvv0_dtw, dvv0_err_dtw = dtw(S1, S2, time, window, fs);\n",
    "    dvt[i]=dvv_dtw\n",
    "    cct[i]=dvv_err_dtw\n",
    "    \n",
    "end\n",
    "\n",
    "dt = map(unix2datetime, dailystk.t);\n",
    "# Assuming datetime_vector is your 71-element Vector{DateTime} \n",
    "# and float_vector is your 71-element Vector{Float64}\n",
    "datetime_vector = dt;  # fill this with your data\n",
    "float_vector = dvt;  # fill this with your data\n",
    "cctfilter = cct;\n",
    "\n",
    "# Combine the vectors into a named tuple which CSV.File will interpret as a table\n",
    "data = (DateTime=datetime_vector, Float=float_vector,cct);\n",
    "\n",
    "dvtf = dvt\n",
    "dtf = dt\n",
    "cctf = cct\n",
    "\n",
    "# Sample datetime_vector and dvtf\n",
    "datetime_vector = dtf;\n",
    "\n",
    "# Assuming dt, dvt, cct, and dailystk are defined\n",
    "#dt = map(unix2datetime, dailystk.t)\n",
    "ticks = dtf[1:10:end]\n",
    "tick = Dates.format.(ticks, \"yyyy-mm-dd\");\n",
    "\n",
    "# First subplot\n",
    "p1 = plot(scatter(dtf, dvtf), seriestype = :line, xticks = (ticks, tick), xrot = -30, ylabel=\"dv/v %\", legend=false)\n",
    "plot!(dtf, dvtf, seriestype = :line, xticks = (ticks, tick), xrot = -30, legend=false)\n",
    "\n",
    "\n",
    "# Second subplot\n",
    "p2 = plot(dtf, cctf, seriestype = :line, ylim = [0, 0.1], label = \"cc\", xticks = (ticks, tick), xrot = -30, left_margin = 10Plots.mm, ylabel=\"error\", xlabel=\"Date\", legend=false)\n",
    "\n",
    "\n",
    "# Third subplot\n",
    "p3 = plot(dailystk, left_margin = 10Plots.mm)\n",
    "\n",
    "# The layout now specifies a grid of 3 rows and 1 column and gives the third plot even more vertical space compared to the first two.\n",
    "l = @layout([a{0.3h}; b{0.2h}; c{0.5h}])\n",
    "\n",
    "# Combine the plots\n",
    "final_plot = plot(p1, p2, p3, layout = l, size = (1100, 1000), left_margin = 20Plots.mm, right_margin = 5Plots.mm)\n",
    "\n",
    "# Save the plot\n",
    "savefig(final_plot, \"$(d.name)_t$(tmin)-$(tmax)_freq$(mnf)-$(mxf)_stk$(ndaystack)clip_dtw_DSV.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40bef3e",
   "metadata": {},
   "source": [
    "## Averaging the DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63710f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "using SeisNoise, SeisIO, Plots\n",
    "using Dates\n",
    "using SeisDvv\n",
    "using CSV\n",
    "using Statistics\n",
    "\n",
    "# Initial setup\n",
    "mnf = 0.1\n",
    "mxf = 0.3\n",
    "ndaystack = 10\n",
    "inter = Day(ndaystack)\n",
    "\n",
    "# Load correlation data\n",
    "d = load_corr(\"/data/wsd02/maleen_data/C_test/OO.HYSB1..BHZ.OO.HYSB1..BHE.jld2\", \"ZE\")\n",
    "#d =load_corr(\"/data/wsd02/maleen_data/Correl_seismic/OO.HYSB1..BHZ.OO.HYSB1..BHE.jld2\",\"ZE\")\n",
    "allstk = stack(d, allstack=true)\n",
    "clean_up!(allstk, mnf, mxf)\n",
    "abs_max!(allstk)\n",
    "dailystk = stack(d, interval=inter)\n",
    "clean_up!(dailystk, mnf, mxf)\n",
    "abs_max!(dailystk)\n",
    "\n",
    "# Parameters for DV/V calculation\n",
    "fs = 40.0     # Sample frequency\n",
    "tmin = 10.0\n",
    "tmax = 60.0\n",
    "dmn = -0.1\n",
    "dmx = 0.1\n",
    "j = size(dailystk.corr, 2)\n",
    "\n",
    "# Initializing arrays for results\n",
    "dvt = zeros(j)\n",
    "cct = zeros(j)\n",
    "cctb = zeros(j)\n",
    "\n",
    "# Function to create an evenly spaced array\n",
    "function evenly_spaced(a, b, n)\n",
    "    h = (b - a) / (n - 1)\n",
    "    collect(a:h:b)\n",
    "end\n",
    "\n",
    "# Averaging function for causal and acausal parts\n",
    "function average_causal_acausal(corr, time)\n",
    "    averaged_corr = copy(corr)\n",
    "    causal_index = findfirst(time .>= 0)\n",
    "    acausal_index = findlast(time .< 0)\n",
    "\n",
    "    for k in 1:causal_index-1\n",
    "        if acausal_index - k + 1 > 0\n",
    "            averaged_corr[causal_index + k - 1] = (averaged_corr[acausal_index - k + 1] + averaged_corr[causal_index + k - 1]) / 2\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return averaged_corr\n",
    "end\n",
    "\n",
    "# Time vector for the correlation function\n",
    "time = evenly_spaced(-100, 100, size(allstk.corr, 1))\n",
    "\n",
    "# Apply averaging to S1\n",
    "S1_averaged = average_causal_acausal(Array(allstk.corr[:]), time)\n",
    "\n",
    "for i in 1:j\n",
    "    S2 = Array(dailystk.corr[:,i])\n",
    "\n",
    "    # Apply averaging to S2\n",
    "    S2_averaged = average_causal_acausal(S2, time)\n",
    "\n",
    "    # Define the window for DV/V calculation\n",
    "    rel_tmin_index = Int(floor((tmin + 100) * fs))\n",
    "    rel_tmax_index = Int(floor((tmax + 100) * fs))\n",
    "    window = collect(rel_tmin_index:rel_tmax_index)\n",
    "\n",
    "    dvv_dtw, dvv_err_dtw, int_dtw, int_err_dtw, dvv0_dtw, dvv0_err_dtw = dtw(S1_averaged, S2_averaged, time, window, fs);\n",
    "    dvt[i]=dvv_dtw\n",
    "    cct[i]=dvv_err_dtw\n",
    "end\n",
    "\n",
    "dt = map(unix2datetime, dailystk.t);\n",
    "# Assuming datetime_vector is your 71-element Vector{DateTime} \n",
    "# and float_vector is your 71-element Vector{Float64}\n",
    "datetime_vector = dt;  # fill this with your data\n",
    "float_vector = dvt;  # fill this with your data\n",
    "cctfilter = cct;\n",
    "\n",
    "dvtf = dvt\n",
    "dtf = dt\n",
    "cctf = cct\n",
    "\n",
    "# Calculate the Interquartile Range (IQR)\n",
    "Q1 = quantile(float_vector, 0.20)\n",
    "Q3 = quantile(float_vector, 0.80)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate the lower and upper bounds to filter the outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the vectors to remove the outliers\n",
    "dtf = DateTime[]\n",
    "dvtf = Float64[]\n",
    "cctf = Float64[]\n",
    "for i in 1:length(float_vector)\n",
    "    if float_vector[i] >= lower_bound && float_vector[i] <= upper_bound\n",
    "        push!(dtf, datetime_vector[i])\n",
    "        push!(dvtf, float_vector[i])\n",
    "        push!(cctf, cctfilter[i])\n",
    "    end\n",
    "end\n",
    "\n",
    "# Sample datetime_vector and dvtf\n",
    "datetime_vector = dtf\n",
    "\n",
    "# Find the minimum and maximum dates in the datetime_vector\n",
    "min_date = minimum(datetime_vector)\n",
    "max_date = maximum(datetime_vector)\n",
    "\n",
    "# Generate all dates in the date rangeI'\n",
    "all_dates = collect(min_date:Day(ndaystack):max_date)\n",
    "\n",
    "# Find the dates that are in all_dates but not in datetime_vector (considering only the date part)\n",
    "missing_dates = setdiff(all_dates, datetime_vector)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming dt, dvt, cct, and dailystk are defined\n",
    "#dt = map(unix2datetime, dailystk.t)\n",
    "ticks = dtf[1:10:end]\n",
    "tick = Dates.format.(ticks, \"yyyy-mm-dd\")\n",
    "\n",
    "# First subplot\n",
    "p1 = plot(scatter(dtf, dvtf), seriestype = :line, xticks = (ticks, tick), xrot = -30, ylabel=\"dv/v %\", legend=false)\n",
    "plot!(dtf, dvtf, seriestype = :line, xticks = (ticks, tick), xrot = -30, legend=false)\n",
    "# For each missing date, add a vertical line to the plot\n",
    "#for date in missing_dates\n",
    "#    vline!(p1, [DateTime(date)], linecolor=:red, linewidth=2, linealpha=0.5, label=\"Missing Date\")\n",
    "#end\n",
    "\n",
    "\n",
    "# Second subplot\n",
    "p2 = plot(dtf, cctf, seriestype = :line, ylim = [0, 0.25], label = \"error\", xticks = (ticks, tick), xrot = -30, left_margin = 10Plots.mm, ylabel=\"error\", xlabel=\"Date\", legend=false)\n",
    "#hline!([0.8], label=\"Threshold\", width=2, color=:red) # Adding a horizontal line at y=0.8\n",
    "\n",
    "# Third subplot\n",
    "p3 = plot(dailystk, left_margin = 10Plots.mm)\n",
    "\n",
    "# The layout now specifies a grid of 3 rows and 1 column and gives the third plot even more vertical space compared to the first two.\n",
    "l = @layout([a{0.3h}; b{0.2h}; c{0.5h}])\n",
    "\n",
    "# Combine the plots\n",
    "final_plot = plot(p1, p2, p3, layout = l, size = (1100, 1000), left_margin = 20Plots.mm, right_margin = 5Plots.mm)\n",
    "\n",
    "# Save the plot\n",
    "savefig(final_plot, \"$(d.name)_t$(tmin)-$(tmax)_freq$(mnf)-$(mxf)_stk$(ndaystack)clip_avg.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dailystk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b2794",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dailystk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b1193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
